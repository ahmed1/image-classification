{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Input, GlobalAveragePooling2D\n",
    "from keras.layers import Add, Flatten, AveragePooling2D, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is one res_layer which we can use to create a deep neural network\n",
    "def res_layer(input_layer, n=64):\n",
    "    L1 = Conv2D(n, (3, 3), padding='same', activation='relu')(input_layer)\n",
    "    L2 = Conv2D(n, (3, 3), padding='same', activation='relu')(L1)\n",
    "    L2 = Conv2D(n, (3, 3), padding='same', activation='relu')(L2)\n",
    "    L3 = Add()([L2, input_layer])\n",
    "    return L3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1064: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# size of cifar10 dataset images\n",
    "main_input = Input(shape=(32,32,3))\n",
    "#all the layers of the res-net\n",
    "L1 = Conv2D(64, (7, 7), strides=(2,2), padding='same', activation='relu')(main_input)\n",
    "L2 = MaxPooling2D(pool_size=(3,3), strides=(2,2))(L1)\n",
    "\n",
    "L2 = res_layer(L2)\n",
    "L2 = res_layer(L2)\n",
    "L2 = res_layer(L2)\n",
    "\n",
    "L3 = AveragePooling2D()(L2)\n",
    "\n",
    "L3 = Flatten()(L3)\n",
    "L4 = Dense(256)(L3)\n",
    "L5 = Dense(10,activation='softmax')(L4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 64)        9472      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "add_1 (Add)                  (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "add_2 (Add)                  (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "add_3 (Add)                  (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               147712    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 492,106\n",
      "Trainable params: 492,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model function from Keras shows map neural network including output shape of each layer and the number of parameters\n",
    "model = Model(main_input, L5)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2578: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 58s - loss: 1.5759 - acc: 0.4306    \n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 61s - loss: 1.2113 - acc: 0.5700    \n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 59s - loss: 1.0544 - acc: 0.6274    \n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 63s - loss: 0.9415 - acc: 0.6678    \n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 58s - loss: 0.8604 - acc: 0.6974    \n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 61s - loss: 0.7896 - acc: 0.7209    \n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 59s - loss: 0.7282 - acc: 0.7441    \n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 62s - loss: 0.6787 - acc: 0.7604    \n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 61s - loss: 0.6314 - acc: 0.7782    \n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 60s - loss: 0.5896 - acc: 0.7937    \n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 59s - loss: 0.5489 - acc: 0.8062    \n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 61s - loss: 0.5136 - acc: 0.8190    \n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 58s - loss: 0.4756 - acc: 0.8331    \n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 59s - loss: 0.4407 - acc: 0.8452    \n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 58s - loss: 0.4095 - acc: 0.8562    \n"
     ]
    }
   ],
   "source": [
    "#load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data() \n",
    "#normalize the input data\n",
    "x_train = x_train.astype('float32')/255 \n",
    "x_test = x_test.astype('float32')/255 \n",
    "y_train = to_categorical(y_train) \n",
    "y_test = to_categorical(y_test) \n",
    "#Optimizer functino used with hyperparameters such as learning rate, decay, and momentum\n",
    "sgd = optimizers.SGD(lr=0.01, decay=5e-4, momentum=0.9, nesterov=True) \n",
    "model.compile(optimizer=sgd, \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy']) \n",
    "history = model.fit(x_train, y_train, epochs=15, shuffle='batch', batch_size=64) \n",
    "f = open('log.txt','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9856/10000 [============================>.] - ETA: 0s0.8599996905326843 0.7354\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test) \n",
    "print(test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is clearly both a high bias and high variance here -- will work to change this in the future"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
