{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, GlobalAveragePooling2D\n",
    "from keras.layers import Add, Flatten, AveragePooling2D, Dense\n",
    "from keras.models import Model\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is one res_layer which we can use to create a deep neural network\n",
    "def res_layer(input_layer, n=64):\n",
    "    L1 = Conv2D(n, (3, 3), padding='same', activation='relu')(input_layer)\n",
    "    L2 = Conv2D(n, (3, 3), padding='same', activation='relu')(L1)\n",
    "    L2 = Conv2D(n, (3, 3), padding='same', activation='relu')(L2)\n",
    "    L3 = Add()([L2, input_layer])\n",
    "    return L3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1064: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# size of cifar10 dataset images\n",
    "main_input = Input(shape=(32,32,3))\n",
    "#all the layers of the res-net\n",
    "L1 = Conv2D(64, (7, 7), strides=(2,2), padding='same', activation='relu')(main_input)\n",
    "L2 = MaxPooling2D(pool_size=(3,3), strides=(2,2))(L1)\n",
    "\n",
    "L2 = res_layer(L2)\n",
    "L2 = res_layer(L2)\n",
    "L2 = res_layer(L2)\n",
    "\n",
    "L3 = AveragePooling2D()(L2)\n",
    "\n",
    "L3 = Flatten()(L3)\n",
    "L4 = Dense(256)(L3)\n",
    "L5 = Dense(10,activation='softmax')(L4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 64)        9472      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "add_1 (Add)                  (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "add_2 (Add)                  (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "add_3 (Add)                  (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               147712    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 492,106\n",
      "Trainable params: 492,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model function from Keras shows map neural network including output shape of each layer and the number of parameters\n",
    "model = Model(main_input, L5)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2578: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 68s - loss: 1.5768 - acc: 0.4294    \n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 65s - loss: 1.2190 - acc: 0.5662    \n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 71s - loss: 1.0486 - acc: 0.6292    \n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 78s - loss: 0.9340 - acc: 0.6716    \n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 72s - loss: 0.8471 - acc: 0.7017    \n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 72s - loss: 0.7782 - acc: 0.7252    \n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 68s - loss: 0.7196 - acc: 0.7477    \n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 70s - loss: 0.6699 - acc: 0.7648    \n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 79s - loss: 0.6233 - acc: 0.7823    \n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 67s - loss: 0.5783 - acc: 0.7959    \n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 68s - loss: 0.5420 - acc: 0.8097    \n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 78s - loss: 0.5030 - acc: 0.8227    \n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 67s - loss: 0.4686 - acc: 0.8370    \n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 69s - loss: 0.4322 - acc: 0.8492    \n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 69s - loss: 0.4030 - acc: 0.8581    \n"
     ]
    }
   ],
   "source": [
    "#load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data() \n",
    "#normalize the input data\n",
    "x_train = x_train.astype('float32')/255 \n",
    "x_test = x_test.astype('float32')/255 \n",
    "y_train = to_categorical(y_train) \n",
    "y_test = to_categorical(y_test) \n",
    "#Optimizer functino used with hyperparameters such as learning rate, decay, and momentum\n",
    "sgd = optimizers.SGD(lr=0.01, decay=5e-4, momentum=0.9, nesterov=True) \n",
    "model.compile(optimizer=sgd, \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy']) \n",
    "history = model.fit(x_train, y_train, epochs=15, shuffle='batch', batch_size=64) \n",
    "f = open('log.txt','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s     \n",
      "0.8689120760917663 0.7295\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test) \n",
    "print(test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('model1.h5')\n",
    "\n",
    "# Recreate the exact same model purely from the file\n",
    "new_model = keras.models.load_model('model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is clearly both a high bias and high variance here -- will work to change this in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x143964518>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e91b8d3a22f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Check that the state is preserved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnew_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_allclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Note that the optimizer state is preserved as well:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check that the state is preserved\n",
    "new_predictions = new_model.predict(x_test)\n",
    "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\n",
    "\n",
    "# Note that the optimizer state is preserved as well:\n",
    "# you can resume training where you left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
